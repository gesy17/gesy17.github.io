---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a final-year CS Ph.D. student at University of Illinois Urbana-Champaign (UIUC), jointly advised by Prof. Jiawei Han and Prof. Hao Peng.


Research Interests
======
* Large Language Model (LLM) Efficiency
* LLM Alignment


Selected Publications
======
* [Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs](https://arxiv.org/abs/2110.08845.pdf) \
**Suyu Ge**\*, Yunan Zhang\*, Liyuan Liu\*, Minjia Zhang, Jiawei Han, Jianfeng Gao. \
*<span style="color:red">ICLR 2024 Outstanding Paper Honorable Mention</span>* 

* [A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts](https://arxiv.org/pdf/2410.01485) \
**Suyu Ge**, Xihui Lin, Yunan Zhang, Jiawei Han, Hao Peng. \
*ArXiv Preprint, 2024* 

* [S2-Attention: Hardware-Aware Context Sharding Among Attention Heads](https://arxiv.org/pdf/2407.17678) \
Xihui Lin\*, Yunan Zhang\*, **Suyu Ge**, Barun Patra, Vishrav Chaudhary, Xia Song. \
*ArXiv Preprint, 2024* 

* [MART: Improving LLM Safety with Multi-Round Automatic Red-Teaming](https://arxiv.org/pdf/2311.07689) \
**Suyu Ge**, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan Wang, Jiawei Han, Yuning Mao. \
*NAACL, 2024* 

For a full publication list, please visit my [Google Scholar](https://gesy17.github.io/publications/)

Experiences
======
* Research Intern at NVIDIA, working on LLM alignment, 2024.01-now
* Research Intern at Meta, worked on LLM safety alignment, 2023.05-2023.12
* Research Intern at Microsoft, worked on retrieval augmented LLM, 2022.05-2022.08

Education
======
* Ph.D. in Computer Science, University of Illinois Urbana-Champaign, 2021-2025